\documentclass[../../main/main.tex]{subfiles}

\begin{document}

\section{Introduction} 

This Review represents an up-to-date summary of  work in the application of artificial intelligence (AI) and machine learning (ML)
in nuclear science, covering topics in nuclear theory, experimental methods, accelerator technology, and nuclear data.


Nuclear physics is a well-established field, with more than a century of fundamental discoveries covering a huge span of degrees of freedom, energy scales and length scales, ranging from our basic understanding of  fundamental constituents of matter  to the structure of stars and the synthesis of the elements in the Cosmos. Experiments 
produce data volumes that range in complexity and heterogeneity, thereby posing enormous challenges to their 
 design,  their execution, and
the statistical data analysis.
 
 Theoretical modeling of nuclear properties is, in most physical cases
 of interest, limited by the large amount of degrees of freedom in
 quantum-mechanical calculations. The analysis of experimental data
 and the theoretical modeling of nuclear systems aims, as is the case
 in all fields of physics, at uncovering the basic laws of motion in
 order to make predictions and estimations, as well as finding
 correlations and causations for strongly interacting matter. The
 broad aims of nuclear physics as a field correspond to a highly
 distributed scientific enterprise. Experimental efforts utilize many
 laboratories worldwide, each with unique operation, data acquisition,
 and analysis methods. Similarly, the scales of focus spanned in
 theoretical nuclear physics lead to broad needs for algorithmic
 methods and uncertainty quantification. These efforts, utilizing
 arrays of data types across size and energy scales, create a perfect
 environment for applications of AI/ML methods.

 \end{document}